{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpk1doz3WrfzF0e7AuSMYt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shareefat/Deep-Learing/blob/main/Loss_functions_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LOSS FUNCTIONS"
      ],
      "metadata": {
        "id": "OsjIgNEhUD-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   a loss function is a mathematical function that measures,how well a model'prediction match the true outcomes\n",
        "*   it probide a quantitative metric for the accuracy od the model's prediction ,which can be used to guide the model's training process.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xg5rSdfnUJC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Types Of Loss Functions"
      ],
      "metadata": {
        "id": "XvW0TZ5VVLmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function come in various forms each for different types of problem\n",
        "\n",
        "\n",
        "#1. Regression Loss Function:\n",
        "\n",
        "in machine learning ,loss function are critical components used to evaluate how well models prediction match the actual value\n",
        "\n",
        "- for regression task where the goal is to predicite a continuos value\n",
        "\n",
        "- popular loss function for regression functions are MSE(Mean Square Error),RMSE,MAE,Huber loss and log cosh loss"
      ],
      "metadata": {
        "id": "-eC5tYoEVQoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Classification Loss Functions\n",
        "\n",
        "- classification loss function are essential for evaluating how well a classification model predictions match the actual class labels\n",
        "\n",
        "- different loss functions are for different classification task like binary, multi call and imbalance dataset\n",
        "\n",
        "- widely used loss funtions Binary cross Entropy loss, Categorical cross entropy loss, Sparse Categorical cross entropy , Kullback leibler Divergence loss, Hinge loss , square Hinge Loss, and Focal loss"
      ],
      "metadata": {
        "id": "RqC9jqQEWFdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. binary Cross Entropy(Log loss)\n",
        "\n",
        "it is used for binary classification problem like 2 variables (0,1)\n",
        "\n",
        "it measure the performance of a classification model whose output is probability value b/w 0 and 1\n",
        "\n",
        "binary cross entropy = 1/n sigma [Yi log (y^i) log (1- y^)]\n",
        "\n",
        "advantage:\n",
        "- suitable for binary problems\n",
        "- differentiable , making it useful for gradient - based optimization\n",
        "\n",
        "disadvantage:\n",
        "- can be sensitive to imbaanced datasets."
      ],
      "metadata": {
        "id": "iajYd2xgXCeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Categorical cross entropy loss\n",
        "- categorical cross entropy loss is used for multiclass classification problem\n",
        "\n",
        "- it measure the performance of classification model whose output is a probability over multiple class\n",
        "\n",
        "categorical cross entropy = - sigma sigma Yij log(Y^ij)\n",
        "\n",
        "yij is the binary indicator (0 or 1) if the label j is the correct classification for data point i and Y^ij is the predicted probability for class j\n",
        "\n",
        "advantage:\n",
        "- suitable for multicall classification\n",
        "- widely used NN\n",
        "\n",
        "dis:\n",
        "- not suitable for sparse target"
      ],
      "metadata": {
        "id": "boJqT5XXYEzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Sparse Categorical cross entropy loss\n",
        "\n",
        "- sparse categorical cross entropy is similar to categorical cross entropy but is used when target label are integer instead of one hot encoded vector\n",
        "\n",
        "\n",
        "advantage:\n",
        "- efficient for large dataset with many classes\n",
        "- reduces meamory usage by using integer labels instead of one hot encoded\n",
        "\n",
        "dis:\n",
        "- requires integer labels."
      ],
      "metadata": {
        "id": "ANhrgMq8ZS6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jbj5gY_LaAYj"
      }
    }
  ]
}